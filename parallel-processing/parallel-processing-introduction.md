# 平行處理簡介

Herb Sutter在[The Pillars of Concurrency](https://www.drdobbs.com/parallel/the-pillars-of-concurrency/200001985?pgno=1)一文中介紹了並發\(concurrent\)程式設計的三種形式：

* 一是非同步模型，即對任務進行粒度劃分並投遞到任務的執行單元中去排程執行；
* 二是平行計算，如何利用支援並行的資料結構和演算法來利用CPU資源，提高系統的吞吐量及拓展性；
* 三是利用一些同步手段確保可變的共享資源的一致性。

## 為什麼需要支援非同步模型呢？

多核\(multi-core\)處理器幾乎無處不在。軟體程式往往越來越多的由使用了位於單個機器或跨網路的多個核的各元件組成。現代程式語言需要提供對這種平行的支援。

同時，響應性已成為越來越不可或缺的軟體品質。響應性的意思是在進行IO操作時不是阻塞住等待它的完成。在伺服器端不阻塞一個worker執行緒、而讓它繼續做其他的事情，待操作完成後等待下一個任務。在客戶端不阻塞主執行緒或GUI執行緒，否則將使程式變得反應遲鈍。

因此能寫非同步程式碼對於管理IO操作的延遲越來越重要。例如，在WinRT中有一個規則，所有耗時超過50ms的IO密集型API只提供非同步介面，甚至沒有傳統的阻塞式介面可呼叫。

## 非同步模型

**非同步模型無非是指將任務進行劃分，在其他執行單元中獨立地執行，通過非同步訊息來進行通訊，來避免阻塞互動執行緒或其他重要執行緒**。同時，這種做法便於也對分離的任務進行測試。



非同步模型最典型的應用是將耗時的任務的建立與執行分離，避免阻塞GUI主執行緒，保證使用者與應用程式的互動得到及時的響應。不僅是耗時的計算任務\(比如後台計算\)，一些可能阻塞的IO任務\(比如等待鎖，或是網路服務的響應\)也會阻塞主執行緒。



在非同步模型中，獨立的任務一般會通過訊息佇列\(而通過不是共享對象\)的方式來完成通訊。以桌面應用程式為例，開發者常常會選擇一些非常成熟的基於訊息佇列的事件驅動模型。



目前最常見的非同步模型的實現是通過將任務打包到執行緒池中進行執行，這樣前端頁面所執行的執行緒能保證對使用者的動作進行實時的反饋，兩者通過訊息佇列或者類似於訊息的抽象\(如Java Future, .NET IAsyncResult\)來進行通訊。

## 平行計算

**平行計算要要解決的問題是儘可能地利用可用的核心來加速並行任務的計算**。比如使用並行的資料結構或演算法來對容器\(或其他對象的集合\)進行操作。新的硬體在計算能力上的停滯不前使得單執行緒程式的計算能力受到限制。另一方面，新的硬體提供了更多的CPU核心來支援多執行緒計算的並發能力。如何順應這種潮流來加速並行任務的執行，對我們編寫應用程式也提出了挑戰。



伸縮性的關鍵並不在於將耗時任務劃分到固定數量的執行緒中，比如遊戲程式常會劃分出計算執行緒，渲染執行緒和其他輔助執行緒。這種做法使得應用程式更傾向於在固定數量\(比如K\)的核心上執行，這無疑降低了程式在其他沒有那麼多核心的機器上的表現。儘管有些應用場景下硬體配置是固定的，像是遊戲程式的結構一般保持固定，但是這種做法並沒有足夠的伸縮性來適應更多的並行。



相反，伸縮性的關鍵在於保證程式能適應不同尺度的輸入\(比如訊息的數量，容器的尺寸\)。主要的做法有兩種：

* 一是使用一些三方庫或者抽象手段來表達你想要做的事情，而不是如何去做。就目前來說，我們可以使用一些像OpenMP的工具來並行地執行一個迴圈，在執行時來決定如何適當的劃分任務來利用現用的核心。
* 二是通過既有的框架並行地執行任務。比如我們可以向執行緒池\(如Java ThreadPoolExecutor or .NET BackgroundWorker\)中提交任務。但是要留意的是任務的提交也是有損失的，所以我們要確定任務是值得提交的。舉例來說，當我們推導一個迭代演算法像快速排序時，演算法的每一步都需要並行地對左右子串進行排序，當子串很小時我們需要特別處理。

## 同步

**同步手段可以幫助我們正確地處理共享資源。現如今的通常做法是通過鎖來控制對共享對象的訪問**。儘管鎖有這樣或那樣的問題，但是它仍是處理一般問題最好的工具。儘管一些框架提供了通過原子變數實現的無鎖資料結構\(如hash tables\)，但這種做法並不是通用的。因為一些通用的資料結構暫時沒有無鎖的實現。所以，還是必須學著使用鎖。

## 平行系統分類

根據指令流和資料流的不同，通常把計算機系統分為：

* 單指令流單資料流（SISD）
* 單指令流多資料流（SIMD）
* 多指令流單資料流（MISD）
* 多指令流多資料流（MIMD）

平行計算機系統絕大部分為MIMD系統，包括

* 平行向量機（PVP，Parallel Vector Processor）；
* 對稱多處理機（SMP, Symmetric Multiprocessor）；
* 大規模並行處理機（MPP，Massively Parallel Processor）；
* 叢集（Cluster）；
* 分佈式共享儲存多處理機（DSM，Distributied Shared Memory） 

### 對稱多處理機 \(SMP\)

* SMP系統一般使用商品化微處理器，具有晶片上或外接快取記憶體。  經由高速匯流排（或交叉開關）連向共享儲存器。每個處理器可等同地訪問共享儲存器、I/O裝置和操作系統服務。
* 單一作業系統映像，全系統只有一個作業系統駐留在共享儲存器中，它根據各個處理器的負載情況，動態地分配各個程序到各個處理器，並保持負載平衡；
* 低通訊延遲，各個行程通過讀/寫作業系統提供的共享資料快取區來完成處理器間的通訊，其延遲通常小於網路通訊延遲；
* 共享匯流排頻寬，所有處理器共享匯流排頻寬，完成對記憶體模組和I/O模組的訪問。
* 問題：欠可靠，匯流排、儲存器、作業系統失效可能導致系統崩潰；

  * 可擴充套件性較差，由於所有處理器都共享匯流排頻寬，而匯流排頻寬每3年才增加2倍，趕不上處理器速度和儲存容量的增長步伐，因此SMP的處理器個數一般少於64個，且只能提供每秒數百億次的浮點運算。





### 叢集（Cluster）

叢集的每個系統都是一個完整的工作站，一個節點可以是一臺PC或SMP。各個節點一般由商品化的網路互連，節點上的網路介面是鬆散耦合到I/O匯流排上的。每個節點一般有本地磁碟，一個完整的作業系統駐留在每個節點上。

## 平行程式設計方法

### 隱式平行程式設計

* 常用傳統的語言程式設計成順序程式碼，把「平行」的工作交給編譯器實現自動平行化。
* 程式的自動並行化是一個理想目標，存在難以克服的困難。
* 語言容易，編譯器難。

### 顯式並行程序設計

* 在使用者程式中出現「平行」的排程語句  。
* 顯式並行是目前有效的並行程序設計方法。例如通過訊息傳遞方式或多執行緒等。
* 語言難，編譯器容易。

## 平行程式設計模型

* 隱式平行（implicit parallel）
* 資料並行（data parallel）
* 共享變數（shared variable）
* 訊息傳遞（message passing）

### 隱式平行（implicit parallel）

程式設計師用熟悉的序列語言編寫相應的序列程式再通過編譯器和執行支援系統將序列程式自動轉化為平行程式碼。

特點是語義簡單、可移植性好、單執行緒，易於除錯和驗證正確性，細粒度並行但效率很低。

### 資料並行（data parallel）

為SIMD的自然模型。

特點是平行操作于聚合資料結構（陣列），松散同步，單一地址空間，隱式互動作用。

優點為程式設計相對簡單，串序平行程式一致。

缺點是程式的效能在很大程度上依賴於所用的編譯系統及使用者對編譯系統的瞭解。且平行粒度侷限於資料級並行，粒度較小。

### 共享變數（shared variable）

為SMP, DSM的自然模型。

特點為多執行緒如SPMD, MPMD，松散同步，單一地址空間，顯式同步，隱式數據分佈，隱式通訊。

典型代表實作為OpenMP。

### 訊息傳遞（message passing）

MPP、COW的自然模型。

特點是多行程非同步並行，多地址空間，顯式同步，顯式數據對映和負載分配，顯式通訊。

典型代表實作為MPI與PVM。

















### 















